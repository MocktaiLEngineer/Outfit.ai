{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-FashionClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-T4Kd5nTzhP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "import os \n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([ transforms.ToPILImage(),\n",
        "                                  transforms.Resize(256),\n",
        "                                  transforms.CenterCrop(224),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                       [0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "TlHXgdgOT0iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionDataset(Dataset):\n",
        "  def __init__(self,csv_file,root_dir,transform):\n",
        "    self.annotations = pd.read_csv(csv_file, dtype={\n",
        "                     'article_id': str,\n",
        "                     'product_type_name': int\n",
        "                 })\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    image_path = os.path.join(self.root_dir, '0' + str(self.annotations.iloc[index,0]) + '.jpg')\n",
        "    image = io.imread(image_path)\n",
        "    y_label = torch.tensor(self.annotations.iloc[index,1])\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return (image,y_label)"
      ],
      "metadata": {
        "id": "SIGVJl3pX6pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_73BRBfXY7Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the images\n",
        "import zipfile\n",
        "root_path = './'\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(root_path)"
      ],
      "metadata": {
        "id": "pyDkQKiIY-uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "-s-yH5f3ZJRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "num_classes = 14\n",
        "learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "num_epochs = 10 "
      ],
      "metadata": {
        "id": "zqW11u8rZFoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "dataset = FashionDataset(csv_file=\"articles_final.csv\",root_dir=\"data\", transform= transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "validation_size = len(dataset) - (train_size + test_size)\n",
        "train_set,test_set, validation_set = torch.utils.data.random_split(dataset,[train_size,test_size,validation_size])\n",
        "train_loader = DataLoader(train_set,batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_set,batch_size,shuffle=True)\n",
        "validate_loader = DataLoader(validation_set,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "9FemCJ37X4XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "KtgmpfloaUQh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze pretrained model parameters to avoid backpropogating through them\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Change the final layer of ResNet50 Model for Transfer Learning\n",
        "fc_inputs = model.fc.in_features\n",
        "\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(fc_inputs, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(256, num_classes), # Since 14 possible outputs\n",
        "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
        ")\n",
        "\n",
        "\n",
        "# The last layer (FC2) will output the probabilities of 14 classes.\n",
        "\n",
        "model.fc = classifier"
      ],
      "metadata": {
        "id": "-0vi_BMIaUt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "CRoyrVLzQa0f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GkzbK4Jiakcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for the validation pass\n",
        "def validation(model, validateloader, criterion):\n",
        "    \n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in iter(validateloader):\n",
        "        \n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        output = model.forward(images)\n",
        "        val_loss += criterion(output, labels).item()\n",
        "\n",
        "        probabilities = torch.exp(output)\n",
        "        \n",
        "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return val_loss, accuracy"
      ],
      "metadata": {
        "id": "EAVZiG6xa9HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier\n",
        "\n",
        "def train_classifier():\n",
        "\n",
        "      epochs = 15\n",
        "      steps = 0\n",
        "      print_every = 40\n",
        "\n",
        "      model.to('cuda')\n",
        "\n",
        "      for e in range(epochs):\n",
        "      \n",
        "          model.train()\n",
        "  \n",
        "          running_loss = 0\n",
        "  \n",
        "          for images, labels in iter(train_loader):\n",
        "      \n",
        "              steps += 1\n",
        "\n",
        "              images = images.to('cuda')\n",
        "              labels = labels.to('cuda')\n",
        "      \n",
        "              optimizer.zero_grad()\n",
        "      \n",
        "              output = model.forward(images)\n",
        "              loss = criterion(output, labels)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "      \n",
        "              running_loss += loss.item()\n",
        "      \n",
        "              if steps % print_every == 0:\n",
        "              \n",
        "                  model.eval()\n",
        "              \n",
        "                  # Turn off gradients for validation, saves memory and computations\n",
        "                  with torch.no_grad():\n",
        "                      validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
        "          \n",
        "                  print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                        \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                        \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
        "                        \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
        "          \n",
        "                  running_loss = 0\n",
        "                  model.train()\n",
        "                    \n",
        "train_classifier()"
      ],
      "metadata": {
        "id": "yKCDPZzdalJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "\n",
        "    # Do validation on the test set\n",
        "    model.eval()\n",
        "    model.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        accuracy = 0\n",
        "    \n",
        "        for images, labels in iter(test_loader):\n",
        "    \n",
        "            images, labels = images.to('cuda'), labels.to('cuda')\n",
        "    \n",
        "            output = model.forward(images)\n",
        "\n",
        "            probabilities = torch.exp(output)\n",
        "        \n",
        "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        \n",
        "            accuracy += equality.type(torch.FloatTensor).mean()\n",
        "        \n",
        "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
        "        \n",
        "        \n",
        "test_accuracy(model, test_loader)"
      ],
      "metadata": {
        "id": "Y_5SV_o3DxCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"sample_data/resnet50-fashionclassifier.pth\")"
      ],
      "metadata": {
        "id": "CoJunVU3Gy0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the checkpoint\n",
        "\n",
        "def save_checkpoint(model):\n",
        "\n",
        "    idx_to_class = {\n",
        "    0: \"Sweater\",\n",
        "    1: \"Trousers\",\n",
        "    2: \"Hoodie\",\n",
        "    3: \"Skirt\",\n",
        "    4: \"T-shirt\",\n",
        "    5: \"Dress\",\n",
        "    6: \"Shorts\",\n",
        "    7: \"Shirt\",\n",
        "    8: \"Cardigan\",\n",
        "    9: \"Blazer\",\n",
        "    10: \"Jacket\",\n",
        "    11: \"Coat\",\n",
        "    12: \"Polo shirt\",\n",
        "    13: \"Blouse\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "    model.idx_to_class = idx_to_class\n",
        "\n",
        "    checkpoint = {'arch': \"resnet50\",\n",
        "                  'idx_to_class': model.idx_to_class,\n",
        "                  'model_state_dict': model.state_dict()\n",
        "                 }\n",
        "\n",
        "    torch.save(checkpoint, 'checkpoint-resnet50.pth')\n",
        "    \n",
        "save_checkpoint(model)    "
      ],
      "metadata": {
        "id": "vk4o571MDxgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Km5QbfyN_E3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# Function that loads a checkpoint and rebuilds the model\n",
        "\n",
        "def load_checkpoint(filepath):\n",
        "    \n",
        "    checkpoint = torch.load(filepath)\n",
        "    \n",
        "    if checkpoint['arch'] == 'resnet50':\n",
        "        \n",
        "        model = torchvision.models.resnet50(pretrained=True)\n",
        "        \n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "    else:\n",
        "        print(\"Architecture not recognized.\")\n",
        "    \n",
        "    model.idx_to_class = checkpoint['idx_to_class']\n",
        "    \n",
        "    # Build custom classifier\n",
        "    fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 512)),\n",
        "                                    ('fc2', nn.Linear(512, 14)),\n",
        "                                ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "    model.fc = fc\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = load_checkpoint('/content/drive/MyDrive/checkpoint-resnet50.pth')\n",
        "print(model)"
      ],
      "metadata": {
        "id": "o_LhFcHuMmYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tdwIb7e3TCNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}